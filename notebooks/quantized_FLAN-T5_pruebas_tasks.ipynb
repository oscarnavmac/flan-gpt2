{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oscarn/flan-gpt2\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f623d26ff74ebe8688c4db80fd6bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 23:23:36,076 - accelerate.big_modeling - WARNING - You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    }
   ],
   "source": [
    "from models.model_utils import T5Model\n",
    "# model_name = \"OscarNav/flan-flan-t5-large-ft\"\n",
    "model_name = \"google/flan-t5-xl\"\n",
    "\n",
    "wrapped_model = T5Model(model_name, device, quantization=True)\n",
    "model = wrapped_model.get_model()\n",
    "# model.resize_token_embeddings(len(wrapped_model.get_tokenizer()))\n",
    "tokenizer = wrapped_model.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.511022592 GB allocated\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"{torch.cuda.memory_allocated() / 1e9} GB allocated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.eval_utils import Evaluation\n",
    "from data.data_utils import create_instruct_dataset\n",
    "\n",
    "\n",
    "eval = Evaluation(model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "CAUSAL_LM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "## INPUT PROMPT\n",
    "{prompt}\n",
    "## GROUND_TRUTH\n",
    "{completion}\n",
    "## MODEL OUTPUT\n",
    "{prediction}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb366077d6c46d3a8411bb5e2000de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65355eb02b74a588aea69f7d81e6790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281ce29f615947bbb2723c080971fd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Lee Il-hyung is a South Korean film director and screenwriter. Prior to directing his first feature film \"A Violent\n",
       "Prosecutor\" (2016), Lee is an assistant director on films, such as \"The Moonlight of Seoul\" (2008), \"My Way\" (2011)\n",
       "and \"\" (2014), and commercial films.                                                                               \n",
       "\n",
       "Based on the paragraph above can we conclude that \"Il-Hung was born in China\"?                                     \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>entailment                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>neutral                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>contradiction                                                                                                   \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "contradiction                                                                                                      \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "neutral                                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Lee Il-hyung is a South Korean film director and screenwriter. Prior to directing his first feature film \"A Violent\n",
       "Prosecutor\" (2016), Lee is an assistant director on films, such as \"The Moonlight of Seoul\" (2008), \"My Way\" (2011)\n",
       "and \"\" (2014), and commercial films.                                                                               \n",
       "\n",
       "Based on the paragraph above can we conclude that \"Il-Hung was born in China\"?                                     \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0mentailment                                                                                                      \n",
       "\u001b[1;33m • \u001b[0mneutral                                                                                                         \n",
       "\u001b[1;33m • \u001b[0mcontradiction                                                                                                   \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "contradiction                                                                                                      \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "neutral                                                                                                            \n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"anli\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "What are the most important words in the following sentence:                                                       \n",
       "\n",
       "A skier making her way down a snowy mountain.                                                                      \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "['mountain', 'skier', 'way']                                                                                       \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "mountain, skier, way                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "What are the most important words in the following sentence:                                                       \n",
       "\n",
       "A skier making her way down a snowy mountain.                                                                      \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "['mountain', 'skier', 'way']                                                                                       \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "mountain, skier, way                                                                                               \n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"common_gen\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since rajpurkar/squad couldn't be found on the Hugging Face Hub\n",
      "2025-09-07 22:38:59,979 - datasets.load - WARNING - Using the latest cached version of the dataset since rajpurkar/squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /home/oscarn/.cache/huggingface/datasets/rajpurkar___squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Fri Nov 22 00:36:36 2024).\n",
      "2025-09-07 22:38:59,985 - datasets.packaged_modules.cache.cache - WARNING - Found the latest cached dataset configuration 'plain_text' at /home/oscarn/.cache/huggingface/datasets/rajpurkar___squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Fri Nov 22 00:36:36 2024).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6445e38813d43e5862a39c1ab613885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a427d2dc07a45879a2433e48cc2a9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d120d14e3d6e42ceb27d5a7a9a37bf21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecf1bc4c4474e6ebd9b55014834e07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "In 2015-2016, Notre Dame ranked 18th overall among \"national universities\" in the United States in U.S. News &amp;     \n",
       "World Report's Best Colleges 2016. In 2014, USA Today ranked Notre Dame 10th overall for American universities     \n",
       "based on data from College Factual. Forbes.com's America's Best Colleges ranks Notre Dame 13th among colleges in   \n",
       "the United States in 2015, 8th among Research Universities, and 1st in the Midwest. U.S. News &amp; World Report also  \n",
       "lists Notre Dame Law School as 22nd overall. BusinessWeek ranks Mendoza College of Business undergraduate school as\n",
       "1st overall. It ranks the MBA program as 20th overall. The Philosophical Gourmet Report ranks Notre Dame's graduate\n",
       "philosophy program as 15th nationally, while ARCHITECT Magazine ranked the undergraduate architecture program as   \n",
       "12th nationally. Additionally, the study abroad program ranks sixth in highest participation percentage in the     \n",
       "nation, with 57.6% of students choosing to study abroad in 17 countries. According to payscale.com, undergraduate  \n",
       "alumni of University of Notre Dame have a mid-career median salary $110,000, making it the 24th highest among      \n",
       "colleges and universities in the United States. The median starting salary of $55,300 ranked 58th in the same peer \n",
       "group. In 2014 what entity named Notre Dame 10th best of all American universities?                                \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "USA Today                                                                                                          \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "USA Today                                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "In 2015-2016, Notre Dame ranked 18th overall among \"national universities\" in the United States in U.S. News &     \n",
       "World Report's Best Colleges 2016. In 2014, USA Today ranked Notre Dame 10th overall for American universities     \n",
       "based on data from College Factual. Forbes.com's America's Best Colleges ranks Notre Dame 13th among colleges in   \n",
       "the United States in 2015, 8th among Research Universities, and 1st in the Midwest. U.S. News & World Report also  \n",
       "lists Notre Dame Law School as 22nd overall. BusinessWeek ranks Mendoza College of Business undergraduate school as\n",
       "1st overall. It ranks the MBA program as 20th overall. The Philosophical Gourmet Report ranks Notre Dame's graduate\n",
       "philosophy program as 15th nationally, while ARCHITECT Magazine ranked the undergraduate architecture program as   \n",
       "12th nationally. Additionally, the study abroad program ranks sixth in highest participation percentage in the     \n",
       "nation, with 57.6% of students choosing to study abroad in 17 countries. According to payscale.com, undergraduate  \n",
       "alumni of University of Notre Dame have a mid-career median salary $110,000, making it the 24th highest among      \n",
       "colleges and universities in the United States. The median starting salary of $55,300 ranked 58th in the same peer \n",
       "group. In 2014 what entity named Notre Dame 10th best of all American universities?                                \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "USA Today                                                                                                          \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "USA Today                                                                                                          \n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"squad\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosmos QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/oscarn/.cache/huggingface/modules/datasets_modules/datasets/allenai--cosmos_qa/3e18538cbfdb2c04189b16642715f0f6da3e97ed5df0aadcec3641245b2cf157 (last modified on Fri Nov 22 00:37:03 2024) since it couldn't be found locally at allenai/cosmos_qa, or remotely on the Hugging Face Hub.\n",
      "2025-09-07 22:40:36,715 - datasets.load - WARNING - Using the latest cached version of the module from /home/oscarn/.cache/huggingface/modules/datasets_modules/datasets/allenai--cosmos_qa/3e18538cbfdb2c04189b16642715f0f6da3e97ed5df0aadcec3641245b2cf157 (last modified on Fri Nov 22 00:37:03 2024) since it couldn't be found locally at allenai/cosmos_qa, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9fcec0f233457c9dca6008a82e74be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5f86c8f4a2423e85743b24014a924f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1078627ef154912bb5127521fe20955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Read the following article and answer the question.                                                                \n",
       "\n",
       "I also got a really cute shirt from a classmate . Today I will get party light candles . The women who is giving   \n",
       "them to me wanted to know what sent I wanted . I am getting Wild Fern .                                            \n",
       "\n",
       "Why did I get a cute t - shirt from a classmate and a wild fern scented candle from a woman ? OPTIONS:             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>It is my birthday and I got unpleasant gifts from friends .                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>None of the above choices .                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>It is Christmas and I gave unpleasant gifts to friends .                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>It is my birthday and I gave nice gifts to friends .                                                            \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "None of the above choices .                                                                                        \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "None of the above choices.                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Read the following article and answer the question.                                                                \n",
       "\n",
       "I also got a really cute shirt from a classmate . Today I will get party light candles . The women who is giving   \n",
       "them to me wanted to know what sent I wanted . I am getting Wild Fern .                                            \n",
       "\n",
       "Why did I get a cute t - shirt from a classmate and a wild fern scented candle from a woman ? OPTIONS:             \n",
       "\n",
       "\u001b[1;33m • \u001b[0mIt is my birthday and I got unpleasant gifts from friends .                                                     \n",
       "\u001b[1;33m • \u001b[0mNone of the above choices .                                                                                     \n",
       "\u001b[1;33m • \u001b[0mIt is Christmas and I gave unpleasant gifts to friends .                                                        \n",
       "\u001b[1;33m • \u001b[0mIt is my birthday and I gave nice gifts to friends .                                                            \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "None of the above choices .                                                                                        \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "None of the above choices.                                                                                         \n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"cosmos_qa\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ad3c4aad5b4260bc72739359ce797a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704528d2a6564071bc9ef64c7584979f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca04c2a3a424bccaba8911683a02b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad308b98dad14e9b8d5f41e4680f04a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:12<00:00, 12.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "CHAPTER XXXVI.                                                                                                     \n",
       "\n",
       "TOM TRINGLE GETS AN ANSWER.                                                                                        \n",
       "\n",
       "Faddle as he went down into the country made up his mind that the law which required such letters to be delivered  \n",
       "by hand was an absurd law. The post would have done just as well, and would have saved a great deal of trouble.    \n",
       "These gloomy thoughts were occasioned by a conviction that he could not carry himself easily or make himself happy \n",
       "among such \"howling swells\" as these Alburys. If they should invite him to the house the matter would be worse that\n",
       "way than the other. He had no confidence in his dress coat, which he was aware had been damaged by nocturnal       \n",
       "orgies. It is all very well to tell a fellow to be as \"big a swell\" as anybody else, as Tom had told him. But      \n",
       "Faddle acknowledged to himself the difficulty of acting up to such advice. Even the eyes of Colonel Stubbs turned  \n",
       "upon him after receipt of the letter would oppress him.                                                            \n",
       "\n",
       "Nevertheless he must do his best, and he took a gig at the station nearest to Albury. He was careful to carry his  \n",
       "bag with him, but still he lived in hope that he would be able to return to London the same day. When he found     \n",
       "himself within the lodges of Stalham Park he could hardly keep himself from shivering, and, when he asked the      \n",
       "footman at the door whether Colonel Stubbs were there, he longed to be told that Colonel Stubbs had gone away on   \n",
       "the previous day to some--he did not care what--distant part of the globe. But Colonel Stubbs had not gone away.   \n",
       "Colonel Stubbs was in the house.                                                                                   \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  1 </span>What is this chapter called?                                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  2 </span>Who took a job at a station by Albury?                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  3 </span>Did he hope to stay there?                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  4 </span>What did he hope?                                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  5 </span>What did he take along?                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  6 </span>Who did he ask about?                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  7 </span>What was his question?                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  8 </span>Who did he ask?                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  9 </span>What was the answer?                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 10 </span>What was he hoping?                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 11 </span>What did Faddle think was absurd?                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 12 </span>Did he think the mail would be just as good?                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 13 </span>What would be a worse matter?                                                                                  \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  1 </span>TOM TRINGLE GETS AN ANSWER.                                                                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  2 </span>Faddle.                                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  3 </span>No.                                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  4 </span>That he would be able to return to London.                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  5 </span>His bag.                                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  6 </span>Colonel Stubbs.                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  7 </span>Whether Colonel Stubbs were there.                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  8 </span>The footman at the door.                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  9 </span>Colonel Stubbs was in the house.                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 10 </span>That Colonel Stubbs had gone away.                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 11 </span>The law which required such letters to be delivered by hand.                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 12 </span>Yes.                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 13 </span>If they should invite him to the house.                                                                        \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>TOM TRINGLE GETS AN ANSWER 2. Faddle 3. no 4. that he would be able to return to London 5. his bag 6. Colonel   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Stubbs 7. whether Colonel Stubbs were there 8. the footman 9. Colonel Stubbs was in the house. 10. Colonel      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Stubbs had gone away 11. the law which required such letters to be delivered by hand 12. yes 13. If they should \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>invite him to the house                                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "CHAPTER XXXVI.                                                                                                     \n",
       "\n",
       "TOM TRINGLE GETS AN ANSWER.                                                                                        \n",
       "\n",
       "Faddle as he went down into the country made up his mind that the law which required such letters to be delivered  \n",
       "by hand was an absurd law. The post would have done just as well, and would have saved a great deal of trouble.    \n",
       "These gloomy thoughts were occasioned by a conviction that he could not carry himself easily or make himself happy \n",
       "among such \"howling swells\" as these Alburys. If they should invite him to the house the matter would be worse that\n",
       "way than the other. He had no confidence in his dress coat, which he was aware had been damaged by nocturnal       \n",
       "orgies. It is all very well to tell a fellow to be as \"big a swell\" as anybody else, as Tom had told him. But      \n",
       "Faddle acknowledged to himself the difficulty of acting up to such advice. Even the eyes of Colonel Stubbs turned  \n",
       "upon him after receipt of the letter would oppress him.                                                            \n",
       "\n",
       "Nevertheless he must do his best, and he took a gig at the station nearest to Albury. He was careful to carry his  \n",
       "bag with him, but still he lived in hope that he would be able to return to London the same day. When he found     \n",
       "himself within the lodges of Stalham Park he could hardly keep himself from shivering, and, when he asked the      \n",
       "footman at the door whether Colonel Stubbs were there, he longed to be told that Colonel Stubbs had gone away on   \n",
       "the previous day to some--he did not care what--distant part of the globe. But Colonel Stubbs had not gone away.   \n",
       "Colonel Stubbs was in the house.                                                                                   \n",
       "\n",
       "\u001b[1;33m  1 \u001b[0mWhat is this chapter called?                                                                                   \n",
       "\u001b[1;33m  2 \u001b[0mWho took a job at a station by Albury?                                                                         \n",
       "\u001b[1;33m  3 \u001b[0mDid he hope to stay there?                                                                                     \n",
       "\u001b[1;33m  4 \u001b[0mWhat did he hope?                                                                                              \n",
       "\u001b[1;33m  5 \u001b[0mWhat did he take along?                                                                                        \n",
       "\u001b[1;33m  6 \u001b[0mWho did he ask about?                                                                                          \n",
       "\u001b[1;33m  7 \u001b[0mWhat was his question?                                                                                         \n",
       "\u001b[1;33m  8 \u001b[0mWho did he ask?                                                                                                \n",
       "\u001b[1;33m  9 \u001b[0mWhat was the answer?                                                                                           \n",
       "\u001b[1;33m 10 \u001b[0mWhat was he hoping?                                                                                            \n",
       "\u001b[1;33m 11 \u001b[0mWhat did Faddle think was absurd?                                                                              \n",
       "\u001b[1;33m 12 \u001b[0mDid he think the mail would be just as good?                                                                   \n",
       "\u001b[1;33m 13 \u001b[0mWhat would be a worse matter?                                                                                  \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m  1 \u001b[0mTOM TRINGLE GETS AN ANSWER.                                                                                    \n",
       "\u001b[1;33m  2 \u001b[0mFaddle.                                                                                                        \n",
       "\u001b[1;33m  3 \u001b[0mNo.                                                                                                            \n",
       "\u001b[1;33m  4 \u001b[0mThat he would be able to return to London.                                                                     \n",
       "\u001b[1;33m  5 \u001b[0mHis bag.                                                                                                       \n",
       "\u001b[1;33m  6 \u001b[0mColonel Stubbs.                                                                                                \n",
       "\u001b[1;33m  7 \u001b[0mWhether Colonel Stubbs were there.                                                                             \n",
       "\u001b[1;33m  8 \u001b[0mThe footman at the door.                                                                                       \n",
       "\u001b[1;33m  9 \u001b[0mColonel Stubbs was in the house.                                                                               \n",
       "\u001b[1;33m 10 \u001b[0mThat Colonel Stubbs had gone away.                                                                             \n",
       "\u001b[1;33m 11 \u001b[0mThe law which required such letters to be delivered by hand.                                                   \n",
       "\u001b[1;33m 12 \u001b[0mYes.                                                                                                           \n",
       "\u001b[1;33m 13 \u001b[0mIf they should invite him to the house.                                                                        \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0mTOM TRINGLE GETS AN ANSWER 2. Faddle 3. no 4. that he would be able to return to London 5. his bag 6. Colonel   \n",
       "\u001b[1;33m   \u001b[0mStubbs 7. whether Colonel Stubbs were there 8. the footman 9. Colonel Stubbs was in the house. 10. Colonel      \n",
       "\u001b[1;33m   \u001b[0mStubbs had gone away 11. the law which required such letters to be delivered by hand 12. yes 13. If they should \n",
       "\u001b[1;33m   \u001b[0minvite him to the house                                                                                         \n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"coqa\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], max_tokens=150, return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since EdinburghNLP/xsum couldn't be found on the Hugging Face Hub\n",
      "2025-09-07 22:41:22,517 - datasets.load - WARNING - Using the latest cached version of the dataset since EdinburghNLP/xsum couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/oscarn/.cache/huggingface/datasets/EdinburghNLP___xsum/default/1.2.0/40db7604fedb616a9d2b0673d11838fa5be8451c (last modified on Sun Sep  7 16:46:46 2025).\n",
      "2025-09-07 22:41:22,524 - datasets.packaged_modules.cache.cache - WARNING - Found the latest cached dataset configuration 'default' at /home/oscarn/.cache/huggingface/datasets/EdinburghNLP___xsum/default/1.2.0/40db7604fedb616a9d2b0673d11838fa5be8451c (last modified on Sun Sep  7 16:46:46 2025).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5604a5af36194514ac265c7b927585ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Article: Varela, 20, had a trial at Old Trafford last season and is David Moyes's first signing as Manchester      \n",
       "United manager. The defender has made one appearance for Penarol but has nine caps for Uruguay's Under-20 side.    \n",
       "\"I'm very pleased to be a part of this club, one of the best in the world,\" he said after signing a five-year deal.\n",
       "\"As everyone in the world knows, this is a huge club that has won everything and I really hope that continues.\"    \n",
       "Varela is taking part in the Under-20 World Championships, which runs from 21 June to 13 July, in Turkey. Last     \n",
       "week, Penarol head coach Jorge Da Silva, who is reported to have since resigned, said he believed the youngster has\n",
       "earned the move. Da Silva said: \"This is what he deserves. It is a shame to see him go but you can't deny him the  \n",
       "opportunity to join a club like this.\" Rafael was United's regular right-back last season, with Phil Jones and     \n",
       "Chris Smalling also featuring in the role.                                                                         \n",
       "\n",
       "A summary of the above article is?                                                                                 \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "Manchester United have completed the signing Uruguayan right-back Guillermo Varela from Atletico Penarol for an    \n",
       "undisclosed fee.                                                                                                   \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "Uruguayan right-back Dani Varela has signed a five-year contract to join Manchester United from rival club Penarol.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Article: Varela, 20, had a trial at Old Trafford last season and is David Moyes's first signing as Manchester      \n",
       "United manager. The defender has made one appearance for Penarol but has nine caps for Uruguay's Under-20 side.    \n",
       "\"I'm very pleased to be a part of this club, one of the best in the world,\" he said after signing a five-year deal.\n",
       "\"As everyone in the world knows, this is a huge club that has won everything and I really hope that continues.\"    \n",
       "Varela is taking part in the Under-20 World Championships, which runs from 21 June to 13 July, in Turkey. Last     \n",
       "week, Penarol head coach Jorge Da Silva, who is reported to have since resigned, said he believed the youngster has\n",
       "earned the move. Da Silva said: \"This is what he deserves. It is a shame to see him go but you can't deny him the  \n",
       "opportunity to join a club like this.\" Rafael was United's regular right-back last season, with Phil Jones and     \n",
       "Chris Smalling also featuring in the role.                                                                         \n",
       "\n",
       "A summary of the above article is?                                                                                 \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "Manchester United have completed the signing Uruguayan right-back Guillermo Varela from Atletico Penarol for an    \n",
       "undisclosed fee.                                                                                                   \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "Uruguayan right-back Dani Varela has signed a five-year contract to join Manchester United from rival club Penarol.\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"xsum\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoolQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa412ed8cef4067a02900af6f16a92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e0872b5759454c9cc78fd1901f537d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62e46f35dc94d47976b70c5e3398b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e681a60be2c4342aefff1250841edea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "In terms of the parts of the grain (the grass fruit) used in flour--the endosperm or protein/starchy part, the germ\n",
       "or protein/fat/vitamin-rich part, and the bran or fiber part--there are three general types of flour. White flour  \n",
       "is made from the endosperm only. Brown flour includes some of the grain's germ and bran, while whole grain or      \n",
       "wholemeal flour is made from the entire grain, including the bran, endosperm, and germ. Germ flour is made from the\n",
       "endosperm and germ, excluding the bran.                                                                            \n",
       "\n",
       "Is the following statement correct based on the text                                                               \n",
       "\n",
       "is wheat flour and white flour the same thing                                                                      \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>True                                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>False                                                                                                           \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "False                                                                                                              \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "False                                                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "In terms of the parts of the grain (the grass fruit) used in flour--the endosperm or protein/starchy part, the germ\n",
       "or protein/fat/vitamin-rich part, and the bran or fiber part--there are three general types of flour. White flour  \n",
       "is made from the endosperm only. Brown flour includes some of the grain's germ and bran, while whole grain or      \n",
       "wholemeal flour is made from the entire grain, including the bran, endosperm, and germ. Germ flour is made from the\n",
       "endosperm and germ, excluding the bran.                                                                            \n",
       "\n",
       "Is the following statement correct based on the text                                                               \n",
       "\n",
       "is wheat flour and white flour the same thing                                                                      \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0mTrue                                                                                                            \n",
       "\u001b[1;33m • \u001b[0mFalse                                                                                                           \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "False                                                                                                              \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "False                                                                                                              \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"bool_q\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccc36d23f3146799666fe17961a6aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cdaeedc42547cc919f07ddb4ec3aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe48563247164bd89b8376d237294129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7705eae2bd164b37b6351c3dd021b807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:49<00:00, 49.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Create a Python neural network model that takes in a given trajectory of stock prices and predicts the stock price \n",
       "for the next day. [10, 10.4, 10.5, 10.6, 10.7, 10.9, 11]                                                           \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   \n",
       " </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> numpy </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">as</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> np</span><span style=\"background-color: #272822\">                                                                                                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> tensorflow </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">as</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> tf</span><span style=\"background-color: #272822\">                                                                                           </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">create_model</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">():</span><span style=\"background-color: #272822\">                                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    model </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> tf</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">keras</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Sequential([</span><span style=\"background-color: #272822\">                                                                                 </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        tf</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">keras</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">layers</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Dense(</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">64</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, activation</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'relu'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, input_shape</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">7</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, )),</span><span style=\"background-color: #272822\">                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        tf</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">keras</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">layers</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Dense(</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    ])</span><span style=\"background-color: #272822\">                                                                                                            </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    model</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">compile(loss</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'mean_squared_error'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"background-color: #272822\">                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                  optimizer</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'adam'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">                  metrics</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'accuracy'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">])</span><span style=\"background-color: #272822\">                                                                           </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> model</span><span style=\"background-color: #272822\">                                                                                                  </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"background-color: #272822\">                                                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> __name__ </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">==</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"__main__\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">:</span><span style=\"background-color: #272822\">                                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    model </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> create_model()</span><span style=\"background-color: #272822\">                                                                                        </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    input_data </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> np</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">array([[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">10</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">10.4</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">10.5</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">10.6</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">10.7</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">10.9</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">11</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]])</span><span style=\"background-color: #272822\">                                               </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    predictions </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> model</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">predict(input_data)</span><span style=\"background-color: #272822\">                                                                       </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">f\"Predicted stock price for the next day is: {</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">predictions[</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">][</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                      </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   \n",
       "</span>\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "y=x[2] ans=1.0 s1=10 while s1=0: ans+=y if ans1+(s1<span style=\"font-style: italic\">y) or s1==10.5: ret=10 #print(ans, ret) if -1</span>s1&gt;=10 and         \n",
       "ret%10==0 and ani==1: continue ans=ain+1 s1+=y elif -1<span style=\"font-style: italic\">s1&gt;=0 and s1=10: ret=ain+1 ans=ain+1 s1+=y elif -2</span>s1 &gt;=10 and\n",
       "ret%10==0 and ani1: continue ans=ain+1 s1+=y elif -1<span style=\"font-style: italic\">s1=10 and ani==1: ret=ain+1 ans=ain+1 s1+=y elif -1</span>s1=10 and   \n",
       "ret%10==0 and ani1==1: continue ans=ain+1 ans=ain+1 s1+=y a=y+2**s-1 #print(ans, ret)                              \n",
       "ans=a[:-1]+a[1:-1],ans+s1+a[3:-1],ans+s2+a[2:-1] q=3*s-1[0]+s1q(y+1, x); if q==1 or q%10 == 0: a[0], ans=x+a,      \n",
       "y+a[0].                                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Create a Python neural network model that takes in a given trajectory of stock prices and predicts the stock price \n",
       "for the next day. [10, 10.4, 10.5, 10.6, 10.7, 10.9, 11]                                                           \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \n",
       "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnumpy\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mas\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnp\u001b[0m\u001b[48;2;39;40;34m                                                                                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtensorflow\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mas\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtf\u001b[0m\u001b[48;2;39;40;34m                                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mcreate_model\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtf\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkeras\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mSequential\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtf\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkeras\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlayers\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDense\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m64\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mactivation\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrelu\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minput_shape\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m7\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtf\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mkeras\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlayers\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mDense\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcompile\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mloss\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mmean_squared_error\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                  \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34moptimizer\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34madam\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m                  \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmetrics\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34maccuracy\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[48;2;39;40;34m                                                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m__name__\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m==\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m__main__\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcreate_model\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minput_data\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mnp\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34marray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m10\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m10.4\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m10.5\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m10.6\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m10.7\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m10.9\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m11\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                              \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpredictions\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpredict\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minput_data\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                      \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mf\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mPredicted stock price for the next day is: \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpredictions\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                     \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \n",
       "\u001b[0m\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "y=x[2] ans=1.0 s1=10 while s1=0: ans+=y if ans1+(s1\u001b[3my) or s1==10.5: ret=10 #print(ans, ret) if -1\u001b[0ms1>=10 and         \n",
       "ret%10==0 and ani==1: continue ans=ain+1 s1+=y elif -1\u001b[3ms1>=0 and s1=10: ret=ain+1 ans=ain+1 s1+=y elif -2\u001b[0ms1 >=10 and\n",
       "ret%10==0 and ani1: continue ans=ain+1 s1+=y elif -1\u001b[3ms1=10 and ani==1: ret=ain+1 ans=ain+1 s1+=y elif -1\u001b[0ms1=10 and   \n",
       "ret%10==0 and ani1==1: continue ans=ain+1 ans=ain+1 s1+=y a=y+2**s-1 #print(ans, ret)                              \n",
       "ans=a[:-1]+a[1:-1],ans+s1+a[3:-1],ans+s2+a[2:-1] q=3*s-1[0]+s1q(y+1, x); if q==1 or q%10 == 0: a[0], ans=x+a,      \n",
       "y+a[0].                                                                                                            \n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"python_code\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], max_tokens=1000, return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eng-Spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "No he decidido a qué trabajo voy a presentarme. How do you say this sentence in English?                           \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "I haven't decided which job to apply for.                                                                          \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "I have not decided what to submit.                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "No he decidido a qué trabajo voy a presentarme. How do you say this sentence in English?                           \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "I haven't decided which job to apply for.                                                                          \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "I have not decided what to submit.                                                                                 \n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"eng_spa\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f08742b47084d4997deadd18c893fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb688a6f95840f98934b979f287b7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f914bc6b96749c4ac1fbc6556f23a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Kabir Suman recorded several albums under the name of Suman Chattopaddhyay or Suman Chatterjee between 1992 and    \n",
       "1999 . Suman Chatterjee , recorded a number of albums between 1992 and 1999 under the name Suman Chattopaddhyay or \n",
       "Kabir Suman . Are these sentences conveying the same meaning? OPTIONS:                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>No                                                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Yes                                                                                                             \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "No                                                                                                                 \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "No                                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Kabir Suman recorded several albums under the name of Suman Chattopaddhyay or Suman Chatterjee between 1992 and    \n",
       "1999 . Suman Chatterjee , recorded a number of albums between 1992 and 1999 under the name Suman Chattopaddhyay or \n",
       "Kabir Suman . Are these sentences conveying the same meaning? OPTIONS:                                             \n",
       "\n",
       "\u001b[1;33m • \u001b[0mNo                                                                                                              \n",
       "\u001b[1;33m • \u001b[0mYes                                                                                                             \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "No                                                                                                                 \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "No                                                                                                                 \n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"paws\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72192cecaf8e4956a062a75eaa8e2ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/56402 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "When will liberals realize that the reason Trump is so successful is because he represents everything liberals     \n",
       "hate?                                                                                                              \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "No. Trump just represents HATE, and his worshippers eat it up and spew it out.                                     \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "until liberals realize that Trump is the reason Trump is successful                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "When will liberals realize that the reason Trump is so successful is because he represents everything liberals     \n",
       "hate?                                                                                                              \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "No. Trump just represents HATE, and his worshippers eat it up and spew it out.                                     \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "until liberals realize that Trump is the reason Trump is successful                                                \n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"quora\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef8ce481d864eae8414e1fed0914a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18a6126500e4a9799451070fd8fec85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fd7878279c444fa8673ddcf1caf573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/20100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6d46d804364fa09c21c3db0f684441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:11<00:00, 11.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Write a function to calculate the factorial of a given number.                                                     \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "def factorial(n): if n == 0: return 1 return n * factorial(n-1)                                                    \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "a = int(c-1) f = int(a+1) i=1 count = 0 while(i+1=5 and a%i==0) : while i=5: if a<span style=\"font-style: italic\">i+i!=0: f=f+i</span>i i+=1 count+=1 i+=1 \n",
       "print(f)                                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Write a function to calculate the factorial of a given number.                                                     \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "def factorial(n): if n == 0: return 1 return n * factorial(n-1)                                                    \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "a = int(c-1) f = int(a+1) i=1 count = 0 while(i+1=5 and a%i==0) : while i=5: if a\u001b[3mi+i!=0: f=f+i\u001b[0mi i+=1 count+=1 i+=1 \n",
       "print(f)                                                                                                           \n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"alpaca\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
