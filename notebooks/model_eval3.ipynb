{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oscarn/flan-gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarn/miniconda3/envs/transformers-311/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import T5Model\n",
    "from eval_utils import Evaluation\n",
    "from data_utils import create_instruct_dataset\n",
    "import csv\n",
    "\n",
    "model_name = \"google/flan-t5-large\"\n",
    "\n",
    "wrapped_model = T5Model(model_name, device)\n",
    "\n",
    "model = wrapped_model.get_model()\n",
    "tokenizer = wrapped_model.get_tokenizer()\n",
    "\n",
    "eval = Evaluation(model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashline = '-'.join('' for x in range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluacion Cualitativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da5121ddae94a5a995fbb0b6aeb8951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d20fc4533c4e829d6a8e72b8b64dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e3ed00ebc5451caa9eea472a5c9513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "William Mercer Cook (January 27, 1869 – July 19, 1944), better known as Will Marion Cook, was an African-American composer and violinist from the United States. Cook was a student of Antonín Dvořák and performed for King George V among others. He is probably best known for his popular songs and Broadway musicals, such as \"\" and \"In Dahomey\".\n",
      "Does this next sentence follow, given the preceding text?\n",
      "William Mercer Cook performed for King George more than once.\n",
      "\n",
      "OPTIONS:\n",
      "- entailment\n",
      "- neutral\n",
      "- contradiction\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "neutral\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "Yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"anli\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=True)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoolQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62e714810e04a809df4efdeaf33b10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3270 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc1392d67584dfcb716e30b65d57ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53c8d3ced364f3ead8732499dcb1a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9b99fb3295436bb677e39cab6934f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Central Bank of India has approached the Reserve Bank of India (RBI) for permission to open representative offices in five more locations - Singapore, Dubai, Doha and London.\n",
      "\n",
      "Is the following statement correct based on the text\n",
      "\n",
      "is central bank of india and reserve bank of india same\n",
      "\n",
      "OPTIONS:\n",
      "- True\n",
      "- False\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "False\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"bool_q\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=True)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "What are the most important words in the following sentence:\n",
      "\n",
      "looking up at a child climbing a tree .\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "['tree', 'look', 'climb']\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "climb, look, tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"common_gen\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=True)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7196a69d277445eade78a95ca530624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Summarize this article:\n",
      "\n",
      "Alongside a picture of him waving goodbye, the 35-year-old Spain international wrote on Twitter: \"Lived it. Loved it. Farewell beautiful game.\"\n",
      "He won club honours with Liverpool, Real Madrid and Bayern and the World Cup and two European Championships.\n",
      "Alonso told Bayern's TV channel: \"It wasn't an easy decision to make, but I believe it's the right time.\n",
      "He added: \"I always thought it would be better to quit sooner rather than later. I still feel good, but I believe this is the right moment.\"\n",
      "Alonso joined Liverpool from Real Sociedad in 2004 and was part of a famous Champions League victory in Istanbul in his first season as the Reds came back from 3-0 down at half-time to beat AC Milan on penalties. He also claimed an FA Cup, a Uefa Super Cup and a Community Shield during his time at Anfield.\n",
      "He moved to Real Madrid in 2009 and won a second Champions League as well as the Spanish title before a switch to Germany in 2014, where he has helped Bayern win two Bundesliga titles and reach the quarter-finals of this year's Champions League - courtesy of a 10-2 aggregate win over Arsenal on Tuesday.\n",
      "Alonso played 114 times for Spain and scored 16 goals as the national side won the 2008 and 2012 European Championships, either side of their maiden World Cup triumph in South Africa in 2010. His final appearance for his country came at the 2014 World Cup in Brazil.\n",
      "Media playback is not supported on this device\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "Bayern Munich midfielder Xabi Alonso has confirmed he will retire when his contract expires in the summer.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "San Mames, Bayern Munich winger, has announced he has retired from football, ending an illustrious career.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"xsum\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=True)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1801836d76470bad00d2c090171c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560f94cab4c54b69b85e713b36d51664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f23fa0c7f48c4cf68061ca229e211745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6f9118868c45969eccde128d25807d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:04<00:00,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Write a loop in Python that accumulates the sum of the numbers in an array. [1, 2, 3]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "```python\n",
      "sum = 0\n",
      "\n",
      "for num in [1, 2, 3]:\n",
      "    sum += num\n",
      "\n",
      "print(sum)\n",
      "```\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "s = 0,0 ; while(True): if(s > 0): s += 1 break ; elif(s > 0): s -= 1 ; s += 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"python_code\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=True, max_tokens=1000)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosmos QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201aafc1c6dd4367ae3f4aad4c8033c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35150281f86c40709c3d57707dcdbb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b408976b9076412f8312d3536ae44869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "I rolled onto my back and gasped for breath . He pulled away from my crotch and put his hand on my heart . I barely noticed it touch my hot , bare skin . \" I think that 's enough for the night then .\n",
      "\n",
      "Answer the following question: Why do you think he decided that it was enough for the night ?\n",
      "OPTIONS:\n",
      "- I had been complaining that I was tired and he did not listen to me until finally deciding to listen to me and leave me be\n",
      "- None of the above choices .\n",
      "- I was hot and gasping and tired and could not go on anymore\n",
      "- He had had enough of my company and wanted to be alone\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "I was hot and gasping and tired and could not go on anymore\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "I was hot and gasping and tired and could not go on anymore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"cosmos_qa\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=True)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5285b1214a4b229fb803e284c5d0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f6c5c70c70484fbcda9707dc488869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65657c45046454fa0de099bf7e68ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3422f26343cb4ea4bdfc9a97983a0ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Article: In addition to the General Assembly Hall, the Parliament also used buildings rented from the City of Edinburgh Council. The former administrative building of Lothian Regional Council on George IV Bridge was used for the MSP's offices. Following the move to Holyrood in 2004 this building was demolished. The former Midlothian County Buildings facing Parliament Square, High Street and George IV Bridge in Edinburgh (originally built as the headquarters of the pre-1975 Midlothian County Council) housed the Parliament's visitors' centre and shop, whilst the main hall was used as the Parliament's principal committee room.\n",
      "\n",
      "Now answer this question: What  former administrative building was used for the MSP's offices?\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "Lothian Regional Council\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "Lothian Regional Council on George IV Bridge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"squad\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=True)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion Cuantitativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b371b22c9b4bff87485d0718bc44b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c19804723400daf3db3339bf08d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072cc5f46b734e198df987d68695e52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... :   0%|          | 0/500 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Generating predictions... : 100%|██████████| 500/500 [03:15<00:00,  2.56it/s]\n"
     ]
    }
   ],
   "source": [
    "res_anli = eval.evaluate(\"anli\", 500, training_set=True, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0217ac75b34b169839f84cf0625211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3ea4e64eef4a2fac46967f92f42807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aed329ef33f410aaba5aa758f9572ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc9e01ed4b84300b3b91069153dc601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... :  43%|████▎     | 214/500 [00:56<01:13,  3.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... : 100%|██████████| 500/500 [02:10<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "res_boolq = eval.evaluate(\"bool_q\", 500, training_set=True, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 500/500 [08:17<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "res_commongen = eval.evaluate(\"common_gen\", 500, training_set=True, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be8a14c760a48cc86c39cdc916733ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... :   0%|          | 0/200 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "Generating responses... : 100%|██████████| 200/200 [07:42<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "res_xsum = eval.evaluate(\"xsum\", 200, training_set=True, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_pythoncode = eval.evaluate(\"python_code\", 200, training_set=False, return_full_text=True, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12616387ec3d42d8a08199416aa909d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b34d68d3df4dceafd77b40cf68b518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e71bc6ca4f347a7901c431310ebe788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... : 100%|██████████| 500/500 [04:21<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "res_cosmosqa = eval.evaluate(\"cosmos_qa\", 500, training_set=True, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5e1ccdce724163aae7a222766add4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff7969a9d24492a4df9e2aa6065c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35d608c58064dda96d1af491f92c26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77ed557761941e487f152b755bbf3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... :  15%|█▌        | 76/500 [00:30<02:30,  2.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 500/500 [03:29<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "res_squad = eval.evaluate(\"squad\", 500, training_set=True, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c0e5022ca74a18a00ce2e4b2d5a7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6908a3176041bca53f0c1cb96aac24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac4c0d49563438f8eac1cea9e1403ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2946f9b1e84312bc09ccca7cb2c5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 200/200 [17:36<00:00,  5.28s/it]\n"
     ]
    }
   ],
   "source": [
    "res_coqa = eval.evaluate(\"coqa\", 200, training_set=True, return_full_text=True, max_tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_engspa = eval.evaluate(\"eng_spa\", 500, training_set=False, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cbc39d51154fc1b2d2486a00a3d356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcf3efe07a14ac78e91ebd1beb49aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381280d5c6ed42ab91a9ef11fb9119ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... : 100%|██████████| 500/500 [02:10<00:00,  3.82it/s]\n"
     ]
    }
   ],
   "source": [
    "res_paws = eval.evaluate(\"paws\", 500, training_set=True, return_full_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy on ANLI is 0.292\n",
      "Total accuracy on BoolQ is 0.634\n",
      "Rouge-1 score on Common Gen is 0.4212127983355881\n",
      "Rouge-LSum score on XSum is 0.26845551016616065\n",
      "Total accuracy on CosmosQA is 0.36\n",
      "RougeLSum score on Squad is 0.9185435131177073\n",
      "RougeLSum score on CoQA is 0.7827169933589246\n",
      "Total accuracy on PAWS is 0.528\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total accuracy on ANLI is {res_anli}\")\n",
    "print(f\"Total accuracy on BoolQ is {res_boolq}\")\n",
    "print(f\"Rouge-1 score on Common Gen is {res_commongen}\")\n",
    "print(f\"Rouge-LSum score on XSum is {res_xsum}\")\n",
    "#print(f\"BLEU score on Python Code is {res_pythoncode}\")\n",
    "print(f\"Total accuracy on CosmosQA is {res_cosmosqa}\")\n",
    "print(f\"RougeLSum score on Squad is {res_squad}\")\n",
    "print(f\"RougeLSum score on CoQA is {res_coqa}\")\n",
    "#print(f\"BLEU score on Eng-Spa is {res_engspa}\")\n",
    "print(f\"Total accuracy on PAWS is {res_paws}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
