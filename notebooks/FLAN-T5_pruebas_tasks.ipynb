{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oscarn/flan-gpt2\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model_utils import T5Model\n",
    "# model_name = \"OscarNav/flan-flan-t5-large-ft\"\n",
    "model_name = \"google/flan-t5-large\"\n",
    "\n",
    "wrapped_model = T5Model(model_name, device)\n",
    "model = wrapped_model.get_model()\n",
    "# model.resize_token_embeddings(len(wrapped_model.get_tokenizer()))\n",
    "tokenizer = wrapped_model.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.eval_utils import Evaluation\n",
    "from data.data_utils import create_instruct_dataset\n",
    "\n",
    "\n",
    "eval = Evaluation(model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "CAUSAL_LM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "## INPUT PROMPT\n",
    "{prompt}\n",
    "## GROUND_TRUTH\n",
    "{completion}\n",
    "## MODEL OUTPUT\n",
    "{prediction}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a1084617084fe493c84938f2f72d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c7f2d550b84dcfbb8786aa8d62e14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e7317f3d814a3a9bd97913f07b4989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "The 1919 Washington State Cougars football team was an American football team that represented Washington State    \n",
       "College during the 1919 college football season. Head coach Gus Welch led the team to a 2–2 mark in the PCC and 5–2\n",
       "overall. This year marked the team's adoption of the \"Cougars\" nickname. Does this next sentence follow, given the \n",
       "preceding text? The cougars played during 1919                                                                     \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>entailment                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>neutral                                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>contradiction                                                                                                   \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "entailment                                                                                                         \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "Yes                                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "The 1919 Washington State Cougars football team was an American football team that represented Washington State    \n",
       "College during the 1919 college football season. Head coach Gus Welch led the team to a 2–2 mark in the PCC and 5–2\n",
       "overall. This year marked the team's adoption of the \"Cougars\" nickname. Does this next sentence follow, given the \n",
       "preceding text? The cougars played during 1919                                                                     \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0mentailment                                                                                                      \n",
       "\u001b[1;33m • \u001b[0mneutral                                                                                                         \n",
       "\u001b[1;33m • \u001b[0mcontradiction                                                                                                   \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "entailment                                                                                                         \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "Yes                                                                                                                \n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"anli\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Generate a sentence that includes all the following words: ['fly', 'cloud', 'plane']                               \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "flying plane against a cloud .                                                                                     \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "plane flying between the clouds                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Generate a sentence that includes all the following words: ['fly', 'cloud', 'plane']                               \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "flying plane against a cloud .                                                                                     \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "plane flying between the clouds                                                                                    \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"common_gen\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since rajpurkar/squad couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'plain_text' at /home/oscarn/.cache/huggingface/datasets/rajpurkar___squad/plain_text/0.0.0/7b6d24c440a36b6815f21b70d25016731768db1f (last modified on Fri Nov 22 00:36:36 2024).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ba4c82c1cb4a77b5c7c103df1ecc20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040741cac0cf404b96090d2d5637b50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50250d41bf84e7c9b41840d76459f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee612f6167d48e3ad9fa4e590e17134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Read this and answer the question                                                                                  \n",
       "\n",
       "The university is affiliated with the Congregation of Holy Cross (Latin: Congregatio a Sancta Cruce, abbreviated   \n",
       "postnominals: \"CSC\"). While religious affiliation is not a criterion for admission, more than 93% of students      \n",
       "identify as Christian, with over 80% of the total being Catholic. Collectively, Catholic Mass is celebrated over   \n",
       "100 times per week on campus, and a large campus ministry program provides for the faith needs of the community.   \n",
       "There are multitudes of religious statues and artwork around campus, most prominent of which are the statue of Mary\n",
       "on the Main Building, the Notre Dame Grotto, and the Word of Life mural on Hesburgh Library depicting Christ as a  \n",
       "teacher. Additionally, every classroom displays a crucifix. There are many religious clubs (catholic and           \n",
       "non-Catholic) at the school, including Council #1477 of the Knights of Columbus (KOC), Baptist Collegiate Ministry \n",
       "(BCM), Jewish Club, Muslim Student Association, Orthodox Christian Fellowship, The Mormon Club, and many more. The \n",
       "Notre Dame KofC are known for being the first collegiate council of KofC, operating a charitable concession stand  \n",
       "during every home football game and owning their own building on campus which can be used as a cigar lounge.       \n",
       "Fifty-seven chapels are located throughout the campus.                                                             \n",
       "\n",
       "How many chapels are on the Notre Dame campus?                                                                     \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "Fifty-seven                                                                                                        \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "Fifty-seven                                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Read this and answer the question                                                                                  \n",
       "\n",
       "The university is affiliated with the Congregation of Holy Cross (Latin: Congregatio a Sancta Cruce, abbreviated   \n",
       "postnominals: \"CSC\"). While religious affiliation is not a criterion for admission, more than 93% of students      \n",
       "identify as Christian, with over 80% of the total being Catholic. Collectively, Catholic Mass is celebrated over   \n",
       "100 times per week on campus, and a large campus ministry program provides for the faith needs of the community.   \n",
       "There are multitudes of religious statues and artwork around campus, most prominent of which are the statue of Mary\n",
       "on the Main Building, the Notre Dame Grotto, and the Word of Life mural on Hesburgh Library depicting Christ as a  \n",
       "teacher. Additionally, every classroom displays a crucifix. There are many religious clubs (catholic and           \n",
       "non-Catholic) at the school, including Council #1477 of the Knights of Columbus (KOC), Baptist Collegiate Ministry \n",
       "(BCM), Jewish Club, Muslim Student Association, Orthodox Christian Fellowship, The Mormon Club, and many more. The \n",
       "Notre Dame KofC are known for being the first collegiate council of KofC, operating a charitable concession stand  \n",
       "during every home football game and owning their own building on campus which can be used as a cigar lounge.       \n",
       "Fifty-seven chapels are located throughout the campus.                                                             \n",
       "\n",
       "How many chapels are on the Notre Dame campus?                                                                     \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "Fifty-seven                                                                                                        \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "Fifty-seven                                                                                                        \n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"squad\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosmos QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/oscarn/.cache/huggingface/modules/datasets_modules/datasets/allenai--cosmos_qa/3e18538cbfdb2c04189b16642715f0f6da3e97ed5df0aadcec3641245b2cf157 (last modified on Fri Nov 22 00:37:03 2024) since it couldn't be found locally at allenai/cosmos_qa, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924cecf280bc4140b544753947647c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388d490de698447191756d8d6dac968a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e291fcea0247c0949e5b33b9ac5be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Answer the question about text:                                                                                    \n",
       "\n",
       "But I wish I had Nathan or Caleb Lawrence -- or some other nephew or neice with me -- Wendy -- or Amanda -- or     \n",
       "Andrew -- or Isaac -- and their older sister -- I do n't know if she hunts . My luck comes when I hunt with the    \n",
       "younger hunters . Indeed -- when I hunt with Caleb Swann -- at least on occaision I see deer -- and actually get to\n",
       "shoot at them . And on at least two occaisions Caleb Swann has shot as well .                                      \n",
       "\n",
       "What may be your reason for wanting to hunt with your nephews ? OPTIONS:                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>I think I can give good fortune to the youth .                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>I want to help them shoot a deer .                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>My nephew asked to hunt with me .                                                                               \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>I think the youth attracts good fortune .                                                                       \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "I think the youth attracts good fortune .                                                                          \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "I think the youth attracts good fortune.                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Answer the question about text:                                                                                    \n",
       "\n",
       "But I wish I had Nathan or Caleb Lawrence -- or some other nephew or neice with me -- Wendy -- or Amanda -- or     \n",
       "Andrew -- or Isaac -- and their older sister -- I do n't know if she hunts . My luck comes when I hunt with the    \n",
       "younger hunters . Indeed -- when I hunt with Caleb Swann -- at least on occaision I see deer -- and actually get to\n",
       "shoot at them . And on at least two occaisions Caleb Swann has shot as well .                                      \n",
       "\n",
       "What may be your reason for wanting to hunt with your nephews ? OPTIONS:                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0mI think I can give good fortune to the youth .                                                                  \n",
       "\u001b[1;33m • \u001b[0mI want to help them shoot a deer .                                                                              \n",
       "\u001b[1;33m • \u001b[0mMy nephew asked to hunt with me .                                                                               \n",
       "\u001b[1;33m • \u001b[0mI think the youth attracts good fortune .                                                                       \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "I think the youth attracts good fortune .                                                                          \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "I think the youth attracts good fortune.                                                                           \n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"cosmos_qa\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce869c1fb37a4f86bd2f8774a4f92996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7a5fb95aca485cb05f13cba1eb2777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640ef424aeea48aa8153130132a333e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492628ca275c4d18b0e5c47e95175384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:11<00:00, 11.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Make use of the article to answer the questions.                                                                   \n",
       "\n",
       "With an estimated population of 1,381,069 as of July 1, 2014, San Diego is the eighth-largest city in the United   \n",
       "States and second-largest in California. It is part of the San Diego–Tijuana conurbation, the second-largest       \n",
       "transborder agglomeration between the US and a bordering country after Detroit–Windsor, with a population of       \n",
       "4,922,723 people. San Diego is the birthplace of California and is known for its mild year-round climate, natural  \n",
       "deep-water harbor, extensive beaches, long association with the United States Navy and recent emergence as a       \n",
       "healthcare and biotechnology development center.                                                                   \n",
       "\n",
       "Historically home to the Kumeyaay people, San Diego was the first site visited by Europeans on what is now the West\n",
       "Coast of the United States. Upon landing in San Diego Bay in 1542, Juan Rodríguez Cabrillo claimed the entire area \n",
       "for Spain, forming the basis for the settlement of Alta California 200 years later. The Presidio and Mission San   \n",
       "Diego de Alcalá, founded in 1769, formed the first European settlement in what is now California. In 1821, San     \n",
       "Diego became part of the newly-independent Mexico, which reformed as the First Mexican Republic two years later. In\n",
       "1850, it became part of the United States following the Mexican–American War and the admission of California to the\n",
       "union.                                                                                                             \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  1 </span>When did San Diego become part of the United States?                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  2 </span>What group of people is it historically a home to?                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  3 </span>Is it the largest city in the United States?                                                                   \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  4 </span>What is the population?                                                                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  5 </span>Who claimed the by for Spain?                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  6 </span>What year was that?                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  7 </span>What happened in 1821?                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  8 </span>What is the weather there?                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  9 </span>Are there beaches?                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 10 </span>What military branch is based there?                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 11 </span>Is became part of the US after what war?                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 12 </span>Is it the largest city in California?                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 13 </span>It is called the \"what\" of California?                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 14 </span>What else it is known for?                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 15 </span>What is it part of?                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 16 </span>What is that?                                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 17 </span>Who is first largest?                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 18 </span>When Juan Cabrillo claimed it, what basis did it form?                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 19 </span>How many years later?                                                                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 20 </span>What did independent Mexico reform into?                                                                       \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  1 </span>1850                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  2 </span>Kumeyaay people                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  3 </span>No                                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  4 </span>1,381,069                                                                                                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  5 </span>uan Rodríguez Cabrillo                                                                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  6 </span>1542                                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  7 </span>It became part of the newly-independent Mexico                                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  8 </span>mild year-round climate,                                                                                       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">  9 </span>Yes                                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 10 </span>United States Navy                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 11 </span>Mexican–American War                                                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 12 </span>no                                                                                                             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 13 </span>birthplace                                                                                                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 14 </span>recent emergence as a healthcare and biotechnology development center.                                         \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 15 </span>San Diego–Tijuana conurbation                                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 16 </span>agglomeration between the US and a bordering country                                                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 17 </span>Detroit–Windsor                                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 18 </span>the settlement of Alta California                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 19 </span>200                                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 20 </span>First Mexican Republic                                                                                         \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span>1850 2. Kumeyaay people 3. no 4. 1,381,069 5. Juan Rodrguez Cabrillo 6. 1542 7. San Diego became part of the    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>newly-independent Mexico 8. mild year-round climate 9. Yes 10. United States Navy 11. Mexican–American War 12.  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>no 13. birthplace 14. recent emergence as a healthcare and biotechnology development center 15. San             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Diego–Tijuana conurbation 16. the second-largest transborder agglomeration between the US and a bordering       \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>country after Detroit–Windsor, 17. Detroit–Windsor 18. the settlement of Alta California 19. 200 20. the First  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>Mexican Republic                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Make use of the article to answer the questions.                                                                   \n",
       "\n",
       "With an estimated population of 1,381,069 as of July 1, 2014, San Diego is the eighth-largest city in the United   \n",
       "States and second-largest in California. It is part of the San Diego–Tijuana conurbation, the second-largest       \n",
       "transborder agglomeration between the US and a bordering country after Detroit–Windsor, with a population of       \n",
       "4,922,723 people. San Diego is the birthplace of California and is known for its mild year-round climate, natural  \n",
       "deep-water harbor, extensive beaches, long association with the United States Navy and recent emergence as a       \n",
       "healthcare and biotechnology development center.                                                                   \n",
       "\n",
       "Historically home to the Kumeyaay people, San Diego was the first site visited by Europeans on what is now the West\n",
       "Coast of the United States. Upon landing in San Diego Bay in 1542, Juan Rodríguez Cabrillo claimed the entire area \n",
       "for Spain, forming the basis for the settlement of Alta California 200 years later. The Presidio and Mission San   \n",
       "Diego de Alcalá, founded in 1769, formed the first European settlement in what is now California. In 1821, San     \n",
       "Diego became part of the newly-independent Mexico, which reformed as the First Mexican Republic two years later. In\n",
       "1850, it became part of the United States following the Mexican–American War and the admission of California to the\n",
       "union.                                                                                                             \n",
       "\n",
       "\u001b[1;33m  1 \u001b[0mWhen did San Diego become part of the United States?                                                           \n",
       "\u001b[1;33m  2 \u001b[0mWhat group of people is it historically a home to?                                                             \n",
       "\u001b[1;33m  3 \u001b[0mIs it the largest city in the United States?                                                                   \n",
       "\u001b[1;33m  4 \u001b[0mWhat is the population?                                                                                        \n",
       "\u001b[1;33m  5 \u001b[0mWho claimed the by for Spain?                                                                                  \n",
       "\u001b[1;33m  6 \u001b[0mWhat year was that?                                                                                            \n",
       "\u001b[1;33m  7 \u001b[0mWhat happened in 1821?                                                                                         \n",
       "\u001b[1;33m  8 \u001b[0mWhat is the weather there?                                                                                     \n",
       "\u001b[1;33m  9 \u001b[0mAre there beaches?                                                                                             \n",
       "\u001b[1;33m 10 \u001b[0mWhat military branch is based there?                                                                           \n",
       "\u001b[1;33m 11 \u001b[0mIs became part of the US after what war?                                                                       \n",
       "\u001b[1;33m 12 \u001b[0mIs it the largest city in California?                                                                          \n",
       "\u001b[1;33m 13 \u001b[0mIt is called the \"what\" of California?                                                                         \n",
       "\u001b[1;33m 14 \u001b[0mWhat else it is known for?                                                                                     \n",
       "\u001b[1;33m 15 \u001b[0mWhat is it part of?                                                                                            \n",
       "\u001b[1;33m 16 \u001b[0mWhat is that?                                                                                                  \n",
       "\u001b[1;33m 17 \u001b[0mWho is first largest?                                                                                          \n",
       "\u001b[1;33m 18 \u001b[0mWhen Juan Cabrillo claimed it, what basis did it form?                                                         \n",
       "\u001b[1;33m 19 \u001b[0mHow many years later?                                                                                          \n",
       "\u001b[1;33m 20 \u001b[0mWhat did independent Mexico reform into?                                                                       \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m  1 \u001b[0m1850                                                                                                           \n",
       "\u001b[1;33m  2 \u001b[0mKumeyaay people                                                                                                \n",
       "\u001b[1;33m  3 \u001b[0mNo                                                                                                             \n",
       "\u001b[1;33m  4 \u001b[0m1,381,069                                                                                                      \n",
       "\u001b[1;33m  5 \u001b[0muan Rodríguez Cabrillo                                                                                         \n",
       "\u001b[1;33m  6 \u001b[0m1542                                                                                                           \n",
       "\u001b[1;33m  7 \u001b[0mIt became part of the newly-independent Mexico                                                                 \n",
       "\u001b[1;33m  8 \u001b[0mmild year-round climate,                                                                                       \n",
       "\u001b[1;33m  9 \u001b[0mYes                                                                                                            \n",
       "\u001b[1;33m 10 \u001b[0mUnited States Navy                                                                                             \n",
       "\u001b[1;33m 11 \u001b[0mMexican–American War                                                                                           \n",
       "\u001b[1;33m 12 \u001b[0mno                                                                                                             \n",
       "\u001b[1;33m 13 \u001b[0mbirthplace                                                                                                     \n",
       "\u001b[1;33m 14 \u001b[0mrecent emergence as a healthcare and biotechnology development center.                                         \n",
       "\u001b[1;33m 15 \u001b[0mSan Diego–Tijuana conurbation                                                                                  \n",
       "\u001b[1;33m 16 \u001b[0magglomeration between the US and a bordering country                                                           \n",
       "\u001b[1;33m 17 \u001b[0mDetroit–Windsor                                                                                                \n",
       "\u001b[1;33m 18 \u001b[0mthe settlement of Alta California                                                                              \n",
       "\u001b[1;33m 19 \u001b[0m200                                                                                                            \n",
       "\u001b[1;33m 20 \u001b[0mFirst Mexican Republic                                                                                         \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m1850 2. Kumeyaay people 3. no 4. 1,381,069 5. Juan Rodrguez Cabrillo 6. 1542 7. San Diego became part of the    \n",
       "\u001b[1;33m   \u001b[0mnewly-independent Mexico 8. mild year-round climate 9. Yes 10. United States Navy 11. Mexican–American War 12.  \n",
       "\u001b[1;33m   \u001b[0mno 13. birthplace 14. recent emergence as a healthcare and biotechnology development center 15. San             \n",
       "\u001b[1;33m   \u001b[0mDiego–Tijuana conurbation 16. the second-largest transborder agglomeration between the US and a bordering       \n",
       "\u001b[1;33m   \u001b[0mcountry after Detroit–Windsor, 17. Detroit–Windsor 18. the settlement of Alta California 19. 200 20. the First  \n",
       "\u001b[1;33m   \u001b[0mMexican Republic                                                                                                \n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"coqa\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], max_tokens=150, return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since EdinburghNLP/xsum couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /home/oscarn/.cache/huggingface/datasets/EdinburghNLP___xsum/default/1.2.0/40db7604fedb616a9d2b0673d11838fa5be8451c (last modified on Sat Sep  6 23:14:34 2025).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eefd7fa3474627811c97743f3d4f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Summarize this article in one sentence.                                                                            \n",
       "\n",
       "Stirling's Lewis McLear struck the post early, while at the other end team-mate Steven Doris cleared a Jamie Duff  \n",
       "header off his own line. The Binos reasserted themselves and Sean Dickson forced City goalkeeper Mark Hurst into a \n",
       "spectacular save. After the break, Darren Smith made a burst through the middle for the hosts but fired just wide. \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "Elgin City slipped out of the League Two promotion play-off zone with a goalless draw at Stirling Albion.          \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "City pushed Forthbank forward with a powerful first half showing as the Scots took the points in a 0-0 draw at     \n",
       "Hamilton Academical.                                                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Summarize this article in one sentence.                                                                            \n",
       "\n",
       "Stirling's Lewis McLear struck the post early, while at the other end team-mate Steven Doris cleared a Jamie Duff  \n",
       "header off his own line. The Binos reasserted themselves and Sean Dickson forced City goalkeeper Mark Hurst into a \n",
       "spectacular save. After the break, Darren Smith made a burst through the middle for the hosts but fired just wide. \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "Elgin City slipped out of the League Two promotion play-off zone with a goalless draw at Stirling Albion.          \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "City pushed Forthbank forward with a powerful first half showing as the Scots took the points in a 0-0 draw at     \n",
       "Hamilton Academical.                                                                                               \n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"xsum\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BoolQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb3e0cf4bcb4d5d9b147a885b3d4345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaa22f3e89446449effd2e54424fa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8019d6d74b224780b3ddcbf01eb598ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027ff7bb7c5148c6a0ee1353d4b03c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Fool's Gold is a 2008 American adventure-romance film from Warner Bros. Pictures about a recently divorced couple  \n",
       "who rekindle their romantic life while searching for a lost treasure. The film was directed by Andy Tennant and    \n",
       "reunites the How to Lose a Guy in 10 Days stars Matthew McConaughey and Kate Hudson.                               \n",
       "\n",
       "Is it true that is the movie fool's gold a true story?                                                             \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>True                                                                                                            \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>False                                                                                                           \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "False                                                                                                              \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "False                                                                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Fool's Gold is a 2008 American adventure-romance film from Warner Bros. Pictures about a recently divorced couple  \n",
       "who rekindle their romantic life while searching for a lost treasure. The film was directed by Andy Tennant and    \n",
       "reunites the How to Lose a Guy in 10 Days stars Matthew McConaughey and Kate Hudson.                               \n",
       "\n",
       "Is it true that is the movie fool's gold a true story?                                                             \n",
       "\n",
       "OPTIONS:                                                                                                           \n",
       "\n",
       "\u001b[1;33m • \u001b[0mTrue                                                                                                            \n",
       "\u001b[1;33m • \u001b[0mFalse                                                                                                           \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "False                                                                                                              \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "False                                                                                                              \n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"bool_q\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002e2f2c809f45799e3c177bc3b45407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44df55cb27c4e04a01d5fe173d7b313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c78fe09479a4635aadc251ee6ad778a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6874d15f2762417db580eb9f0b5db8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Generate a Python script to sort the given list of words. ['bubble', 'selection', 'quicksort', 'insertion']        \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "<span style=\"background-color: #272822\">                                                                                                                   \n",
       " </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># function to sort the given list of words</span><span style=\"background-color: #272822\">                                                                        </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">sort_words</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(words):</span><span style=\"background-color: #272822\">                                                                                            </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># sort the list of words in alphabetical order</span><span style=\"background-color: #272822\">                                                                </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    words</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sort()</span><span style=\"background-color: #272822\">                                                                                                  </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># print the sorted list of words</span><span style=\"background-color: #272822\">                                                                              </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    print(words)</span><span style=\"background-color: #272822\">                                                                                                  </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># driver code</span><span style=\"background-color: #272822\">                                                                                                     </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">words </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> [</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'bubble'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'selection'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'quicksort'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'insertion'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                         </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">sort_words(words)</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #959077; text-decoration-color: #959077; background-color: #272822\"># output</span><span style=\"background-color: #272822\">                                                                                                          </span>\n",
       "<span style=\"background-color: #272822\"> </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'bubble'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'insertion'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'quicksort'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'selection'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                 </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   \n",
       "</span>\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "bubble, selection, quicksort                                                                                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Generate a Python script to sort the given list of words. ['bubble', 'selection', 'quicksort', 'insertion']        \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \n",
       "\u001b[0m\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# function to sort the given list of words\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34msort_words\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwords\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# sort the list of words in alphabetical order\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwords\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msort\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# print the sorted list of words\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwords\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# driver code\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwords\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbubble\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mselection\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mquicksort\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34minsertion\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msort_words\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mwords\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                                 \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;149;144;119;48;2;39;40;34m# output\u001b[0m\u001b[48;2;39;40;34m                                                                                                         \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbubble\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34minsertion\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mquicksort\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mselection\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                \u001b[0m\u001b[48;2;39;40;34m \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \n",
       "\u001b[0m\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "bubble, selection, quicksort                                                                                       \n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"python_code\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], max_tokens=1000, return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eng-Spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Translate \"Estoy orgulloso de ti.\" from Spanish to English.                                                        \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "I'm proud of you.                                                                                                  \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "I am proud of you.                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Translate \"Estoy orgulloso de ti.\" from Spanish to English.                                                        \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "I'm proud of you.                                                                                                  \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "I am proud of you.                                                                                                 \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"eng_spa\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195b22b30e094139a3934ef380160b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d62d8beffa4fa89bd173dea3fcc4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9fe609fd46409485fe2b771f3e8f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Bullion Express - concept is being introduced new store in Dallas , Texas in Preston Center opened .               \n",
       "\n",
       "2011-DGSE Bullion Express concept is introduced , new store opened in Preston Center in Dallas , Texas             \n",
       "\n",
       "Do the above sentences mean the same thing? OPTIONS:                                                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>No                                                                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>Yes                                                                                                             \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "No                                                                                                                 \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "No                                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Bullion Express - concept is being introduced new store in Dallas , Texas in Preston Center opened .               \n",
       "\n",
       "2011-DGSE Bullion Express concept is introduced , new store opened in Preston Center in Dallas , Texas             \n",
       "\n",
       "Do the above sentences mean the same thing? OPTIONS:                                                               \n",
       "\n",
       "\u001b[1;33m • \u001b[0mNo                                                                                                              \n",
       "\u001b[1;33m • \u001b[0mYes                                                                                                             \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "No                                                                                                                 \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "No                                                                                                                 \n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"paws\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06957a5604d648f9aa86044c7979ca5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/56402 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Can you put magnets on an electric meter to slow it down?                                                          \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "If you believe that it is not accurate call the electric company and have them check it out.                       \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "no                                                                                                                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Can you put magnets on an electric meter to slow it down?                                                          \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "If you believe that it is not accurate call the electric company and have them check it out.                       \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "no                                                                                                                 \n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"quora\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4fe07f346848e5910c643a8749e469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/52002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5acae3dbb945c28a83c093144a4dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95b1204ce2f4e25b62338f448b8f489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/20100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095d974c4feb440787077784aca02d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">INPUT PROMPT</span>                                                    \n",
       "\n",
       "Rewrite the following sentence using active voice. The news report was read by the captain.                        \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">GROUND_TRUTH</span>                                                    \n",
       "\n",
       "The captain read the news report.                                                                                  \n",
       "\n",
       "\n",
       "                                                   <span style=\"font-weight: bold; text-decoration: underline\">MODEL OUTPUT</span>                                                    \n",
       "\n",
       "The captain read the news report.                                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "                                                   \u001b[1;4mINPUT PROMPT\u001b[0m                                                    \n",
       "\n",
       "Rewrite the following sentence using active voice. The news report was read by the captain.                        \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mGROUND_TRUTH\u001b[0m                                                    \n",
       "\n",
       "The captain read the news report.                                                                                  \n",
       "\n",
       "\n",
       "                                                   \u001b[1;4mMODEL OUTPUT\u001b[0m                                                    \n",
       "\n",
       "The captain read the news report.                                                                                  \n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_instruct_dataset(num_samples, [\"alpaca\"])\n",
    "example = dataset[0]\n",
    "prediction = eval.generate([example[\"prompt\"]], return_full_text=not CAUSAL_LM)[0]\n",
    "Markdown(template.format(prompt=example[\"prompt\"], \n",
    "                         completion=example[\"completion\"], \n",
    "                         prediction=prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
