{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oscarn/flan-gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarn/miniconda3/envs/transformers-311/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import GPT2Model\n",
    "from eval_utils import Evaluation\n",
    "from data_utils import create_instruct_dataset\n",
    "import csv\n",
    "\n",
    "model_name = \"gpt2-multitask_V3\"\n",
    "#model_name = \"flan-gpt2-medium-distill_V3\"\n",
    "\n",
    "wrapped_model = GPT2Model(model_name, device)\n",
    "\n",
    "model = wrapped_model.get_model()\n",
    "tokenizer = wrapped_model.get_tokenizer()\n",
    "\n",
    "eval = Evaluation(model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashline = '-'.join('' for x in range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluacion Cualitativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba2b00ff7ba4b83b2c35bcefde54df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3220885681204031b738b0cdc9613d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a5bb9ac7a24a1683c53b64ae81cb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Determine if the sentence is true based on the text below:\n",
      "Dub Taylor was acting in movies right up until the year he died, which was 1994.\n",
      "\n",
      "Walter Clarence Taylor Jr. (February 26, 1907 – October 3, 1994), known as Dub Taylor, was an American character actor who from the 1940s into the 1990s worked extensively in films and on television, often in Westerns but in comedies. He was the father of actor Buck Taylor, who played the character Newly O'Brien on \"Gunsmoke\".\n",
      "OPTIONS:\n",
      "- entailment\n",
      "- neutral\n",
      "- contradiction\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "neutral\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"anli\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=False)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoolQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3267b75efa874ee29c21b622f90cbf64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3270 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0f790be0f6435aaff146b0ac597433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e51c94b67e43bda7b05e583610a962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278ff1b7dfeb4d0abf0ac6ac423ca42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3255 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Sweeney Todd: The Demon Barber of Fleet Street is a 1979 musical thriller with music and lyrics by Stephen Sondheim and book by Hugh Wheeler. The musical is based on the 1973 play Sweeney Todd, the Demon Barber of Fleet Street by Christopher Bond.\n",
      "Based on the above text, what's the best answer to this question: is the barber of seville the same as sweeney todd?\n",
      "\n",
      "OPTIONS:\n",
      "- True\n",
      "- False\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "False\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"bool_q\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=False)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Produce a sentence which mentions all of these concepts: ['wear', 'hand', 'open', 'oyster', 'glove']\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "The worker wears gloves on both hands when opening oysters.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "A man wearing a hat with sunglasses open.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"common_gen\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=False)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8357d12e228e43f2b891874ca8ac1805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Article: Researchers suggest there is poor evidence to support screening and isolating infected patients - standard practice in hospitals worldwide.\n",
      "But good hand hygiene and bathing with antibacterial solutions are key to reducing infections, they say.\n",
      "Experts warn more studies are needed before any change in protocols.\n",
      "Despite rates of Meticillin resistant staphylococcus aureus (MRSA) falling in many countries, concerns about its spread remain.\n",
      "The bug is resistant to most antibiotics and while it is can be carried harmlessly on the skin it may lead to serious wound infections - particularly in people who are already unwell.\n",
      "Hospitals have used a varied combination of methods to tackle it, including:\n",
      "Scientists reviewed studies over the last decade.\n",
      "But most investigated several infection control measures in combination, making it difficult to tease out which ones worked best.\n",
      "Researchers say the limited evidence focusing solely on isolation or screening suggest they may not reduce spread of the disease and could do more harm than good.\n",
      "Prof Gerd Fatkenheuer, from the University Hospital Cologne, Germany, who was part of the research team said: \"In the haste to do something against the rising tide of MRSA infection, measures were adopted that seemed plausible but were not properly assessed, bundling the effective and harmless with the ineffective and harmful.\n",
      "\"We know for example that isolating patients can result in anxiety and depression and fewer visits by doctors and nurses.\"\n",
      "The scientists emphasise evidence backs good hand-washing and suggests people with the bug should bathe daily using antibacterial solutions.\n",
      "Prof Peter Collignon at the Canberra Hospital, Australia said: \"Certain countries, however, that take all of these combined approaches - such as the Netherlands and Denmark - have the lowest rates of MRSA spread in healthcare facilities.\n",
      "\"So we need to make sure that studies clearly show that we will not do harm by stopping some or all of these isolation methods.\"\n",
      "The report authors say as MRSA levels continue to drop this provides a good opportunity to reassess how best to tackle the problem.\n",
      "And they recommend scarce resources could be redeployed to combat other infections - rather than singling out MRSA.\n",
      "Recent figures for England suggest 862 cases of MRSA were recorded in the year 2013-14, a substantial reduction from the 4,451 cases reported in 2007-08.\n",
      "\n",
      "Summarize the main points of that article.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "The jury is still out on the effectiveness of methods to control the hospital superbug MRSA, according to an international report in the Lancet.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "This is the first study highlighting widespread use of antibiotics in GP practices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"xsum\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=False)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3493c2d4a4c84d73b8ac0e6f7ec19dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7beecc5fd754a2e901e690a6baa6384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2602767fb7df41a181396e06d666589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac08ec650c744820b8b599c513b82b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1809 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:01<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Create a Python program to convert a given string from lower to upper case. String: “hello world”\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "```python\n",
      "def convert_to_upper_case(string):\n",
      "    '''This function will take a string as input and convert it to upper case'''\n",
      "    return string.upper()\n",
      "\n",
      "converted_string = convert_to_upper_case(\"hello world\")\n",
      "print(converted_string)\n",
      "```\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "```python\n",
      "import base64\n",
      "\n",
      "str = \"\"\"\n",
      "    'Hello World'\n",
      "\"\"\"\n",
      "\n",
      "def convert_str_to_upper(s):\n",
      "    return s.upper()\n",
      "\n",
      "print(convert_str_to_upper(\"hello world\"))\n",
      "```\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"python_code\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=False, max_tokens=1000)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosmos QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ef712a25d94f5f82eff915425d6467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1725e2128053400aae0ccffecb786f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbe5aea46944263a253e3261be947e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2985 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Although the rest of work yesterday sucked ( marketing ended up approving the override price for the SCD pump , but it did n't go out in time to be delivered next day . And then this morning I got an e - mail saying the item is no longer available to sell in the US market , even though there are still no comments that indicate anything stating that it 's discontinued . So apparently I should n't have done that in the first place , even though I was just trying to do my job lol . Got ta love it ) .\n",
      "\n",
      "Question: What may have caused work to suck yesterday ?\n",
      "OPTIONS:\n",
      "- I did n't get an email regarding the price override .\n",
      "- I had to set an discontinue the SCD pump .\n",
      "- I was n't able to sell a product .\n",
      "- I was n't able to market a product .\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "I was n't able to sell a product .\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "I didn't get an email regarding the price override.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"cosmos_qa\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=False)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b2107c960644a9a961fefcf0419d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc2d4beadee4c2aa5e6b3b57042fb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d15543768844d1b9dd47e43c54f695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10430 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed41a5c7c5914f6fa60b702c30dcfcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 1/1 [00:00<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT \n",
      "Please answer a question about the following article about Victoria_and_Albert_Museum:\n",
      "\n",
      "The glass collection covers 4000 years of glass making, and has over 6000 items from Africa, Britain, Europe, America and Asia. The earliest glassware on display comes from Ancient Egypt and continues through the Ancient Roman, Medieval, Renaissance covering areas such as Venetian glass and Bohemian glass and more recent periods, including Art Nouveau glass by Louis Comfort Tiffany and Émile Gallé, the Art Deco style is represented by several examples by René Lalique. There are many examples of crystal chandeliers both English, displayed in the British galleries and foreign for example Venetian (attributed to Giuseppe Briati) dated c1750 are in the collection. The stained glass collection is possibly the finest in the world, covering the medieval to modern periods, and covering Europe as well as Britain. Several examples of English 16th-century heraldic glass is displayed in the British Galleries. Many well-known designers of stained glass are represented in the collection including, from the 19th century: Dante Gabriel Rossetti, Edward Burne-Jones and William Morris. There is also an example of Frank Lloyd Wright's work in the collection. 20th-century designers include Harry Clarke, John Piper, Patrick Reyntiens, Veronica Whall and Brian Clarke.\n",
      "\n",
      "How many years does the V&A glass collection cover?\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Ground Truth: \n",
      "\n",
      "4000\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION: \n",
      "\n",
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = create_instruct_dataset([\"squad\"], training_set=False)\n",
    "example = dataset[0]\n",
    "prompt, ground_truth = example.values()\n",
    "prediction = eval.generate([prompt], return_full_text=False)[0]\n",
    "print(dashline)\n",
    "print(f'INPUT PROMPT \\n{prompt}')\n",
    "print(dashline)\n",
    "print(f\"Ground Truth: \\n\\n{ground_truth}\")\n",
    "print(dashline)\n",
    "print(f'MODEL GENERATION: \\n\\n{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacion Cuantitativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37d44cbd62b458f83ee40dc6ee14a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f74f4d78474314bc1f2f536a698c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd9b3656a414d0dbc537b7f846e3e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... : 100%|██████████| 500/500 [00:46<00:00, 10.65it/s]\n"
     ]
    }
   ],
   "source": [
    "res_anli = eval.evaluate(\"anli\", 500, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8b7f81397b49daa0001a6f5540384c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604e2821332344f6a0857be0af116c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f9c554ff314e22a15a73ac59b9696a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0722b0471517480ca64d1e9e98c01ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... : 100%|██████████| 500/500 [00:36<00:00, 13.81it/s]\n"
     ]
    }
   ],
   "source": [
    "res_boolq = eval.evaluate(\"bool_q\", 500, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 500/500 [02:36<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "res_commongen = eval.evaluate(\"common_gen\", 500, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10d1556307747cb943d13ede1a7106a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 200/200 [09:14<00:00,  2.77s/it]\n"
     ]
    }
   ],
   "source": [
    "res_xsum = eval.evaluate(\"xsum\", 200, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5c99e9daf74a42ad2cbc584870c7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a124905b394f549cb9ca62a284b21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e9cc96c2084fddab3e633b61099b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/16237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ea78c9e4884c0b99847e4eb3ec135c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 200/200 [11:54<00:00,  3.57s/it]\n"
     ]
    }
   ],
   "source": [
    "res_pythoncode = eval.evaluate(\"python_code\", 200, training_set=True, return_full_text=False, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3177017c9b4617994f0017f717427e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848baa4b11ef4f16a962eff6b8fbf3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/25262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bb351f15654d7091e960f75592bdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... : 100%|██████████| 500/500 [01:12<00:00,  6.92it/s]\n"
     ]
    }
   ],
   "source": [
    "res_cosmosqa = eval.evaluate(\"cosmos_qa\", 500, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b407c5a0d07d4407bac73f2860563cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99dc8851315d4c6eb9ecb87decd0def0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de42624cd8864a7dac9432f1b53717ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/87241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab7ce3534384d7f96b8025a6309d12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 500/500 [01:18<00:00,  6.40it/s]\n"
     ]
    }
   ],
   "source": [
    "res_squad = eval.evaluate(\"squad\", 500, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516d5e34cad740ae98e53afee54bb789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7199 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76acced3183c42f280f094cfca9ca98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4c9ea8eb464f748af3c94b9267d3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bd4782d08d410f91e69f8ca826a61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 200/200 [16:06<00:00,  4.83s/it]\n"
     ]
    }
   ],
   "source": [
    "res_coqa = eval.evaluate(\"coqa\", 200, training_set=True, return_full_text=False, max_tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... :  28%|██▊       | 139/500 [00:57<02:25,  2.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses... : 100%|██████████| 500/500 [03:26<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "res_engspa = eval.evaluate(\"eng_spa\", 500, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b80ef56b02438bae684804e2a1e0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406f212b3ca040cd8090d3dda9b78e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/49401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25ee1a0b26648ff9db7ee1c7d9a0674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions... : 100%|██████████| 500/500 [00:29<00:00, 16.84it/s]\n"
     ]
    }
   ],
   "source": [
    "res_paws = eval.evaluate(\"paws\", 500, training_set=True, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy on ANLI is 0.552\n",
      "Total accuracy on BoolQ is 0.356\n",
      "Rouge-1 score on Common Gen is 0.40430203396758846\n",
      "Rouge-LSum score on XSum is 0.1358498056956292\n",
      "BLEU score on Python Code is 0.20455075418572752\n",
      "Total accuracy on CosmosQA is 0.39\n",
      "RougeLSum score on Squad is 0.5594881024204554\n",
      "RougeLSum score on CoQA is 0.44147678226556475\n",
      "BLEU score on Eng-Spa is 0.11635468697969209\n",
      "Total accuracy on PAWS is 0.532\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total accuracy on ANLI is {res_anli}\")\n",
    "print(f\"Total accuracy on BoolQ is {res_boolq}\")\n",
    "print(f\"Rouge-1 score on Common Gen is {res_commongen}\")\n",
    "print(f\"Rouge-LSum score on XSum is {res_xsum}\")\n",
    "print(f\"BLEU score on Python Code is {res_pythoncode}\")\n",
    "print(f\"Total accuracy on CosmosQA is {res_cosmosqa}\")\n",
    "print(f\"RougeLSum score on Squad is {res_squad}\")\n",
    "print(f\"RougeLSum score on CoQA is {res_coqa}\")\n",
    "print(f\"BLEU score on Eng-Spa is {res_engspa}\")\n",
    "print(f\"Total accuracy on PAWS is {res_paws}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
